{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725924a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 499s 12s/step - loss: 1.5843 - accuracy: 0.5444 - val_loss: 1.1810 - val_accuracy: 0.6208\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 209s 5s/step - loss: 1.1546 - accuracy: 0.5804 - val_loss: 0.9572 - val_accuracy: 0.6483\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 212s 5s/step - loss: 0.8708 - accuracy: 0.6960 - val_loss: 0.7841 - val_accuracy: 0.7125\n",
      "Epoch 4/10\n",
      " 8/41 [====>.........................] - ETA: 2:46 - loss: 0.6876 - accuracy: 0.7656"
     ]
    }
   ],
   "source": [
    "# Importar las librerias \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Definir directorios de los datos\n",
    "# Entrenamiento\n",
    "train_directory = 'CarneDataset/train'\n",
    "# Test\n",
    "test_directory = 'CarneDataset/test'\n",
    "# Parametros de ejecucion se tomara 20% para validacion y el 80% para entrenamiento\n",
    "test_size=0.2\n",
    "random_state=32\n",
    "# Definiciòn de epocas a considerar \n",
    "epochs=10\n",
    "# Definiciòn de numero de imagenes que se le pasa a la red\n",
    "batch_size=32\n",
    "x_train_images = []\n",
    "y_train_labels = []\n",
    "x_test_images = []\n",
    "y_test_labels = []\n",
    "\n",
    "\n",
    "# Contar el  numero de archivos de un directorio\n",
    "def fcount(path):\n",
    "    count = 0\n",
    "    for f in os.listdir(path):\n",
    "        if os.path.isfile(os.path.join(path, f)):\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# Guardar las imagenes de entrenamiento y los nombres de los archivos en listas de entrenamiento y de etiquetas\n",
    "#  Si el directorio esta vacio no se guarda la lista\n",
    "\n",
    "# Leer las imágenes de test y almacenar en las listas de imagenes y etiquetas\n",
    "for label_class in os.listdir(train_directory):\n",
    "    label_directory = os.path.join(train_directory, label_class)\n",
    "    if (fcount(label_directory)) > 0:\n",
    "        for filename in os.listdir(label_directory):\n",
    "            img_path_train = os.path.join(label_directory, filename)\n",
    "            img_train = cv2.imread(img_path_train)\n",
    "            x_train_images.append(img_train)\n",
    "            y_train_labels.append(label_class)\n",
    "           \n",
    "        \n",
    "            \n",
    "# Gurdar las imágenes de test y almacenar en las listas de imagenes y etiquetas\n",
    "for label_class in os.listdir(test_directory):\n",
    "    label_directory = os.path.join(test_directory, label_class)\n",
    "    if (label_class in y_train_labels):    \n",
    "        for filename in os.listdir(label_directory):\n",
    "            img_path_test = os.path.join(label_directory, filename)\n",
    "            img_test = cv2.imread(img_path_test)\n",
    "            x_test_images.append(img_test)\n",
    "            y_test_labels.append(label_class)\n",
    "  \n",
    "      \n",
    "# Convertir las listas de imágenes y etiquetas a matrices NumPy\n",
    "x_train_images = np.array(x_train_images)\n",
    "y_train_labels = np.array(y_train_labels)\n",
    "\n",
    "# Convertir las listas de imágenes y etiquetas de prueba a matrices NumPy\n",
    "x_test_images = np.array(x_test_images)\n",
    "y_test_labels = np.array(y_test_labels)\n",
    "\n",
    "# Normalizar los valores de píxeles de las imágenes de prueba entre 0 y 1\n",
    "x_test_images = x_test_images.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "# Codificar las etiquetas como números one hot encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_labels_encoded = label_encoder.fit_transform(y_train_labels)\n",
    "\n",
    "\n",
    "# Codificar las etiquetas como números one hot encoding\n",
    "y_test_labels_encoded = label_encoder.transform(y_test_labels)\n",
    "\n",
    "\n",
    "# Dividir el conjunto de entrenamiento en entrenamiento y validación\n",
    "x_train_images, x_val_images, y_train_labels_encoded, y_val_labels_encoded = train_test_split(x_train_images, y_train_labels_encoded, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Normalizar los valores de píxeles entre 0 y 1\n",
    "x_train_images = x_train_images.astype('float32') / 255.0\n",
    "x_val_images = x_val_images.astype('float32') / 255.0\n",
    "\n",
    "\n",
    "# Definir la arquitectura de la red CNN\n",
    "model = Sequential()\n",
    "# capa convulcional identifica 32 filtros \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=x_train_images.shape[1:]))\n",
    "# Capa convulcional identifica 32 filtros\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# Capa maxpooling permite reducir las dimensiones de la imagen \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "# % de datos aleatorios a no considerar de las neurones para evitar \n",
    "model.add(Dropout(0.25))\n",
    "# capa convulcional  \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# capa convulcional  \n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# Capa maxpooling permite reducir las dimensiones de la imagen \n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Clasificador \n",
    "model.add(Flatten())\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "\n",
    "# compilamoa el modelo definiendo que utilizamos el optimizador adam\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar modelo datos entrenamiento y datos validación \n",
    "historial= model.fit(x_train_images, y_train_labels_encoded, epochs=epochs, batch_size=batch_size, validation_data=(x_val_images, y_val_labels_encoded))\n",
    "\n",
    "# Verificar las perdidas del modelo\n",
    "plt.xlabel(\"# Epocas\")\n",
    "plt.ylabel(\"Perdidas\")\n",
    "plt.plot(historial.history[\"loss\"])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Probar el modelo con los datos de prueba\n",
    "predictions = model.predict(x_test_images)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calcular la matriz de confusión del modelo\n",
    "matrizconfusion = confusion_matrix(y_test_labels_encoded, predicted_labels)\n",
    "print('MATRIZ DE CONFUSION')\n",
    "print(matrizconfusion)\n",
    "\n",
    "#dataframe = pd.DataFrame(matrizconfusion, range(7), range(7))\n",
    "#plt.figure(figsize=(10,7))\n",
    "#sns.set(font_scale=1.4)\n",
    "#sns.heatmap(dataframe, annot=True, annot_kvs={'size': 12})\n",
    "#plt.show()\n",
    "sns.heatmap(matrizconfusion)\n",
    "plt.show()\n",
    "\n",
    "# Calcular la matriz de confusión del error en prueba\n",
    "test_predictions = model.predict(x_test_images)\n",
    "test_predicted_labels = np.argmax(test_predictions, axis=1)\n",
    "matriz_test_confusion = confusion_matrix(y_test_labels_encoded, test_predicted_labels)\n",
    "\n",
    "print('MATRIZ CONFUSION DEL ERROR DE TEST')\n",
    "print(matriz_test_confusion)\n",
    "\n",
    "# Calcular la matriz de confusión del error en entrenamiento\n",
    "train_predictions = model.predict(x_train_images)\n",
    "train_predicted_labels = np.argmax(train_predictions, axis=1)\n",
    "matriz_train_confusion = confusion_matrix(y_train_labels_encoded, train_predicted_labels)\n",
    "\n",
    "print('MATRIZ CONFUSION DEL ERROR DE ENTRENAMIENTO')\n",
    "print(matriz_train_confusion)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aed629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ba7f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dddf4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f26495",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
